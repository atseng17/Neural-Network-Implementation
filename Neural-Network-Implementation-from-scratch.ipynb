{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'm going to demonstrate how to construct a machine learning model (a neural net) learns to do binary operations such as AND, OR, and XOR.\n",
    "\n",
    "This example only shows the model that does XOR operation, beacuse one can train the AND or OR operation model simply by 1) using the same neural net architechture that is used to train the XOR model and change the labels of the training dataset, or 2) creating a neural net without a hidden layer.\n",
    "\n",
    "The training dataset is simply the XOR truth table that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{array}{|c|c|c|}\n",
       "\\hline \n",
       "A & B & Output \\\\\\hline\n",
       "0 & 0 & 0 \\\\\\hline\n",
       "0 & 1 & 1 \\\\\\hline\n",
       "1 & 0 & 1 \\\\\\hline\n",
       "1 & 1 & 0 \\\\\\hline\n",
       "\\end{array}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex \n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline \n",
    "A & B & Output \\\\\\hline\n",
    "0 & 0 & 0 \\\\\\hline\n",
    "0 & 1 & 1 \\\\\\hline\n",
    "1 & 0 & 1 \\\\\\hline\n",
    "1 & 1 & 0 \\\\\\hline\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that the outputs of XOR operation is not easily seperated by a straight line, such as the AND and OR operation. The model architecture that would be used in this example is the simplest type of a neural net that has a hidden layer between the input layer and the output layer. This hidden layer allows the model to learn a rule to draw a complex boundary between the two classes (True,False). One can increase the number of layers or the number of nodes in the hidden layer as one desires and achieve the same goal. Instead of wasting computational resources, this example only uses one hidden layer with 2 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(99)\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "def sigmoid_d(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "def MSE(pred,target):\n",
    "    return mean_squared_error(pred,target)\n",
    "\n",
    "# Define train dataset: X with labels y\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "# Preprocessing\n",
    "X = X.T\n",
    "\n",
    "#Define model architecture: \n",
    "unit_l1= 2 #nodes in layer1(hidden layer)\n",
    "unit_l2= 1 #nodes in layer2(output)\n",
    "\n",
    "#weights and intercepts\n",
    "W1=np.random.rand(unit_l1,X.shape[0])\n",
    "W2=np.random.rand(unit_l2,unit_l1)\n",
    "b1 = np.random.rand(unit_l1,1)\n",
    "b2 = np.random.rand(unit_l2,1)\n",
    "\n",
    "#learning rate\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost per iters 0: 0.385695\n",
      "Cost per iters 5000: 0.054040\n",
      "Cost per iters 10000: 0.003333\n",
      "Cost per iters 15000: 0.001549\n"
     ]
    }
   ],
   "source": [
    "m = y.shape[1]\n",
    "costs=[]\n",
    "for iters in range(20000):\n",
    "    #Forward path\n",
    "    Z1 = np.matmul(W1,X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2,A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    #Calculating cost\n",
    "    cost = MSE(A2,y.T)\n",
    "    \n",
    "    #Backward path\n",
    "    MSE_d = A2 - y.T\n",
    "    d_Z2 = MSE_d * sigmoid_d(Z2)\n",
    "    d_W2 = np.matmul(d_Z2,A1.T)\n",
    "    d_b2 = np.sum(d_Z2,axis=1,keepdims=True)\n",
    "    \n",
    "    d_A1 = np.matmul(W2.T,d_Z2)\n",
    "    d_Z1 = d_A1 * sigmoid_d(Z1)\n",
    "    d_W1 = np.matmul(d_Z1,X.T)\n",
    "    d_b1 = np.sum(d_Z1,axis=1,keepdims=True)\n",
    "    \n",
    "    #Update\n",
    "    W2 -= d_W2 * lr\n",
    "    b2 -= d_b2 * lr\n",
    "    W1 -= d_W1 * lr\n",
    "    b1 -= d_b1 * lr\n",
    "    if iters % 5000 == 0:\n",
    "        costs.append(cost)\n",
    "        print (\"Cost per iters %i: %f\" %(iters, cost))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97002708]]\n"
     ]
    }
   ],
   "source": [
    "test_set = np.array([[1,0]]).T\n",
    "output_ = sigmoid(np.matmul(W2,sigmoid(np.matmul(W1,test_set) + b1))+ b2)\n",
    "print(output_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
